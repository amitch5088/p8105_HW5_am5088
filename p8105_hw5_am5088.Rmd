---
title: "p8105_hw5_am5088"
author: "Anika Mitchell am5088"
output: github_document
---

load my necessary libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
library(tibble)
library(broom)

knitr::opts_chunk$set(
    fig.width = 6,
    fig.asp = .6,
    out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
    ggplot2.continuous.colour = "viridis",
    ggplot2.continuous.fil = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

I've gone ahead and loaded my necessary libraries and set up plotting for this problem (tidyverse), and will now start to develop a function to address the following question:

Suppose you put ð‘›people in a room, and want to know the probability that at least two people share a birthday. For simplicity, weâ€™ll assume there are no leap years (i.e. there are only 365 days) and that birthdays are uniformly distributed over the year (which is actually not the case).

**Write a function that, for a fixed group size, randomly draws â€œbirthdaysâ€ for each person; checks whether there are duplicate birthdays in the group; and returns TRUE or FALSE based on the result.**


```{r write birthday function}
shared_birthdays = function(n) {
  
  random_birthdays = sample(1:365, size = n, replace = TRUE)
  return(any(duplicated(random_birthdays)))
}
```

Now I'm going to test this function:
```{r test function}

shared_birthdays(40)

```

```{r test function 2}

shared_birthdays(12)

```

Okay, after testing this function, a couple of times it appears that it is working okay. That is, it is able to produce either TRUE or FALSE based on the sample size of n people and if there are any duplicated birthdays in the mix. When I test the function with 40, I get TRUE, and with 12 people I get FALSE. 

**Next, run this function 10000 times for each group size between 2 and 50. For each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs. Make a plot showing the probability as a function of group size, and comment on your results.**

loop function
```{r run the function, echo=TRUE}

results_df = tibble(
  group_size = integer(),
  prob_shared_birthdays = numeric()
)
set.seed
for (i in 2:50) {
   shared_birthdays_loop = replicate(10000, shared_birthdays(i))
   results_df = results_df %>%
    add_row(
      group_size = i,
      prob_shared_birthdays = mean(shared_birthdays_loop)
    )
}

```

check out my table
```{r check out my table}
print(results_df)
```

Plot my results table
```{r plot results table}
ggplot(results_df, aes(x = group_size, y = prob_shared_birthdays)) +
geom_line() +
labs(
  title = "Probability of Shared Birthday In Group Size n",
  x = "Group Size",
  y = "Probability of having a Shared Birthday"
  )
```

This plot confirms what I learned when I tested the function earlier on a smaller sample size like 12 which had a FALSE result (indicating a lower probablity of duplication) vs a larger sample size like 40 which had a TRUE result (indicating a higher probability of duplication) which is what the plot shows. As the group size increases, the probability of people having a shared birthday increases which is why live in a world with a huge sample size (if we could sample the whole world) and a lot of duplicated birthdays across the 365 days we count in Western society. On the other hand in my group of close friends which is less than 10, there are no duplicated birthdays because that probability is lower in a smaller sample. 

## Problem 2

When designing an experiment or analysis, a common question is whether it is likely that a true effect will be detected â€“ put differently, whether a false null hypothesis will be rejected. The probability that a false null hypothesis is rejected is referred to as power, and it depends on several factors, including: the sample size; the effect size; and the error variance. In this problem, you will conduct a simulation to explore power in a one-sample t-test.

```{r run t test}

sim_t_test = function(mu, n = 30, sigma = 5, num_sim = 5000) {
  replicate(num_sim, {
  x = rnorm(n, mean = mu, sd = sigma)
    
  t_test = t.test(x, mu = 0)
    
  broom::tidy(t_test)
  }, simplify = FALSE) %>% 
    bind_rows() %>% 
    mutate(true_mu = mu)
}

```

Repeat the above for ðœ‡={1,2,3,4,5,6}
and complete the following:

Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of ðœ‡
 on the x axis. Describe the association between effect size and power.
Make a plot showing the average estimate of ðœ‡Ì‚ 
 on the y axis and the true value of ðœ‡
 on the x axis. Make a second plot (or overlay on the first) the average estimate of ðœ‡Ì‚ 
 only in samples for which the null was rejected on the y axis and the true value of ðœ‡
 on the x axis. Is the sample average of ðœ‡Ì‚ 
 across tests for which the null is rejected approximately equal to the true value of ðœ‡
? Why or why not?

```{r repeat for different mu values}
repeat_mu_values = 0:6

repeat_mu_df = map_dfr(repeat_mu_values, ~ sim_t_test(mu = .x))
```

plot showing proportion of times null was rejected (power)
```{r plot null rejection frequency}
summary_df = repeat_mu_df %>%
group_by(true_mu) %>%
  summarize(
    power = mean(p.value < 0.05),
    avg_mu_hat = mean(estimate),
    avg_mu_hat_rejected = mean(estimate[p.value < 0.05])
  )

ggplot(summary_df, aes(x = true_mu, y = power)) +
  geom_line() +
  labs(
  title = "Power of the T-Test by true Î¼",
  x = "True Î¼",
  y = "# of null rejections"
  ) +
  theme_minimal()

ggplot(summary_df, aes(x = true_mu)) +
  geom_line(aes(y = avg_mu_hat, color = "All Samples")) +
  geom_line(aes(y = avg_mu_hat_rejected, color = "Rejected Null")) +
  labs(
  title = "Average Estimate of Î¼Ì‚ by True Î¼",
  x = "True Î¼",
  y = "Average Î¼Ì‚") +
  scale_color_manual(
    values = c("All Samples" = "green", "Rejected Null" = "blue"),
    name = "Condition"
  ) +
  theme_minimal()

```


